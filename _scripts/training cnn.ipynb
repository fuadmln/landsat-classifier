{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Script untuk training model CNN dengan Dataset dan menyimpan model\n",
        "\n",
        "**Output yang didapatkan:**\n",
        "*   Model CNN hasil training dalam format .h5\n",
        "*   Plot akurasi & nilai loss pada data training\n",
        "*   Plot akurasi & nilai loss pada data validation\n",
        "*   Akurasi pada data testing\n",
        "\n",
        "**Prasyarat:**\n",
        "*   Memiliki dataset yang sudah displit berupa data training, data validation, dan data testing\n",
        "*   Sudah mengupload data tersebut ke Google Drive\n",
        "\n",
        "**Cara menggunakan:**\n",
        "1. Upload script kode ini ke Google Drive, lalu buka menggunakan Google Colab\n",
        "2. Upload file dataset yang berisi data training, data validation dan data testing ke direktori Google Drive yang diinginkan (format .zip)\n",
        "3. Ubah variabel `gdrive_zip` sesuai lokasi file zip dataset\n",
        "4. Sesuaikan nama folder dataset kalian pada variabel `base_dir`, `training_dir`, `validation_dir` dan `test_dir`\n",
        "5. Atur parameter seperti input size gambar dan epoch\n",
        "6. Tentukan model yang ingin digunakan pada variabel `base_model`\n",
        "7. Tentukan lokasi penyimpanan dan penamaan file model (untuk callback `checkpoint_filepath` dan juga hasil training akhir `model.save()`) \n",
        "8. Tentukan loaksi penyimpanan dan penamaan file history jika ingin menyimpannya\n",
        "9. Jalankan cell satu-persatu\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQ0Fm0ec6uFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DBwnDNUbmsdu"
      },
      "outputs": [],
      "source": [
        "# menghubungkan aplikasi ke Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzL1GkEQnDzk"
      },
      "outputs": [],
      "source": [
        "# memuat dataset\n",
        "import zipfile,os,shutil\n",
        "\n",
        "# ATUR DIREKTORI DATASET\n",
        "gdrive_zip = 'drive/MyDrive/Dataset/EuroSAT 6-2-2.zip'\n",
        "zip_ref = zipfile.ZipFile(gdrive_zip, 'r') # opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') # ekstrak file ke folder /tmp (direktori pada Google Colab)\n",
        "zip_ref.close()\n",
        "\n",
        "# ATUR DIREKTORI FOLDER DATA TRAINING DAN VALIDATION SESUAI NAMA FOLDER\n",
        "base_dir = '/tmp/EuroSAT 6-2-2'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "test_dir = os.path.join(base_dir, 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9XBvSvjopuZ"
      },
      "outputs": [],
      "source": [
        "# ATUR PARAMETER\n",
        "\n",
        "#ukuran default model pada umumnya (resnet, vgg16, densenet): 224px\n",
        "#lebih lengkap untuk dimensi input model dapat dilihat di halaman masing-masing model, https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
        "#ukuran asli dataset eurosat: 64px\n",
        "img_height = 224 # atur dimensi piksel masukan\n",
        "img_width = img_height\n",
        "img_channel = 3\n",
        "\n",
        "batch_size = 64 # jumlah data yang akan diproses dalam satu waktu (pada sekali iterasi training)\n",
        "epoch = 50  # jumlah iterasi training (pada keseluruhan dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpHa-JfJw6Xp"
      },
      "outputs": [],
      "source": [
        "# image generator\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# jika mau atur data augmentation, bisa ubah parameter ImageGenerator() dibawah, baik untuk data training maupun data testing\n",
        "train_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        " \n",
        "val_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255,\n",
        "                    rotation_range=20,\n",
        "                    horizontal_flip=True,\n",
        "                    shear_range = 0.2,\n",
        "                    fill_mode = 'nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir, \n",
        "        target_size=(img_width, img_height), \n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_dir, \n",
        "        target_size=(img_width, img_height),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LC62p7ccxNQh"
      },
      "outputs": [],
      "source": [
        "# image generator untuk data testing\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=1,\n",
        "    class_mode='categorical')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzq4fvW-rCOQ",
        "outputId": "cad883d9-8e99-4e26-ea47-3ee22bc299b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 16200 5400\n"
          ]
        }
      ],
      "source": [
        "num_classes = train_generator.num_classes # informasi jumlah kelas\n",
        "train_img_total = train_generator.samples # informasi jumlah gambar data training\n",
        "val_img_total = validation_generator.samples # informasi jumlah gambar data validation\n",
        "\n",
        "print(num_classes, train_img_total, val_img_total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33TIoptFr9eE"
      },
      "outputs": [],
      "source": [
        "# tentukan model yang akan digunakan. \n",
        "# daftar model yang tersedia dapat dilihat di https://www.tensorflow.org/api_docs/python/tf/keras/applications\n",
        "\n",
        "#base_model = tf.keras.applications.vgg16.VGG16( # model VGG16\n",
        "#base_model = tf.keras.applications.densenet.DenseNet121( # model DenseNet121\n",
        "base_model = tf.keras.applications.resnet50.ResNet50( # model ResNet50                                                 \n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=(img_width, img_height, img_channel),\n",
        "    pooling='avg',\n",
        ")\n",
        "\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "predictions = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "model.summary()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFIF1kW71jsU"
      },
      "outputs": [],
      "source": [
        "# callback untuk menyimpan model ketika mendapatkan akurasi yang lebih tinggi\n",
        "# hal ini penting karena ketika epoch makin tinggi tidak ada jaminan akurasi juga semakin tinggi\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ATUR DIREKTORI DAN PENAMAAN MODEL\n",
        "# jika namanya sama, maka model yg lama akan tereplace\n",
        "checkpoint_filepath = '/content/drive/MyDrive/Landsat/Model/ResNet50 x224.h5'\n",
        "\n",
        "# dynamic naming\n",
        "# contoh penamaan berdasarkan epoch keberapa dan nilai lossnya\n",
        "#checkpoint_filepath = 'weights.{epoch:02d}-{val_loss:.2f}.h5'\n",
        "\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HexhU4xRxO2m"
      },
      "outputs": [],
      "source": [
        "# mulai proses tarining\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = train_img_total//batch_size,\n",
        "    epochs = epoch,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = val_img_total//batch_size,\n",
        "    verbose = 2,\n",
        "    callbacks=[model_checkpoint_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgqjGQbxxahT"
      },
      "outputs": [],
      "source": [
        "# menampilkan grafik akurasi pada proses training & validation\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"lower right\") # atur posisi label\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Urs4pSCaxVZG"
      },
      "outputs": [],
      "source": [
        "# menampilkan grafik nilai loss pada proses training dan validation\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper right\") # atur posisi label\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x03WOgRTz4Vi"
      },
      "outputs": [],
      "source": [
        "# testing model terhadap data testing dengan menghitung akurasi dan nilai loss\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "\n",
        "print('\\nTest accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ivrt6bHvCqXE"
      },
      "outputs": [],
      "source": [
        "# menyimpan model pada epoch terakhir\n",
        "# jika kalian training dengan parameter yang berbeda-beda, \n",
        "# sebaiknya dalam penamaan file tambahkan juga informasi parameter-parameter tersebut (misal nama model, epoch, input size, akurasi dll)\n",
        "\n",
        "model.save('/content/drive/MyDrive/Landsat/Model/ResNet50 x224.h5');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P08hy6RKODTH"
      },
      "outputs": [],
      "source": [
        "# menyimpan history nilai akurasi dan nilai training jika mau\n",
        "\n",
        "import pickle\n",
        "with open('/content/drive/MyDrive/Landsat/history/ResNet50 x224-history.pickle', 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}